{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "88facfc2-7a17-4a44-8b34-29761d350b72",
   "metadata": {},
   "source": [
    "# MusicGen Async SageMaker Inference\n",
    "https://github.com/aws/amazon-sagemaker-examples/blob/main/async-inference/Transcription_on_SM_endpoint.ipynb\n",
    "https://huggingface.co/docs/transformers/model_doc/musicgen#generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dda1f938-35f2-4eee-a319-ac2e199ff29e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install -Uq pip\n",
    "!pip install -Uq sagemaker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "104af8c1-e7ef-42e2-b419-28a899800f01",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!mkdir model\n",
    "!mkdir model/code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bec2f848-b6fa-4320-8e2f-470e04696271",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## requirements.txt https://github.com/facebookresearch/audiocraft/blob/main/README.md\n",
    "'''\n",
    "# Best to make sure you have torch installed first, in particular before installing xformers.\n",
    "# Don't run this if you already have PyTorch installed.\n",
    "pip install 'torch>=2.0'\n",
    "# Then proceed to one of the following\n",
    "pip install -U audiocraft  # stable release\n",
    "pip install -U git+https://git@github.com/facebookresearch/audiocraft#egg=audiocraft  # bleeding edge\n",
    "pip install -e .  # or if you cloned the repo locally (mandatory if you want to train).\n",
    "'''\n",
    "with open(\"model/code/requirements.txt\", \"w\") as f:\n",
    "    f.write(\"transformers==4.34.1\\n\")\n",
    "    f.write(\"boto3\\n\")\n",
    "    f.write(\"torch>=2.0\\n\")\n",
    "    f.write(\"scipy\\n\")\n",
    "    f.write(\"uuid\\n\")\n",
    "    f.write(\"audiocraft\\n\")\n",
    "    f.write(\"git+https://git@github.com/facebookresearch/audiocraft#egg=audiocraft\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7449cccb-5535-4bcc-af1f-9b9ff057ca8b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%writefile model/code/inference.py\n",
    "\n",
    "import boto3\n",
    "from urllib.parse import urlparse\n",
    "from transformers import AutoProcessor, MusicgenForConditionalGeneration\n",
    "import scipy\n",
    "import uuid\n",
    "import torch\n",
    "import os\n",
    "\n",
    "\n",
    "def model_fn(model_dir):\n",
    "    model = MusicgenForConditionalGeneration.from_pretrained(\"facebook/musicgen-large\")\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    model.to(device)\n",
    "    return model\n",
    "\n",
    "\n",
    "def process_input(data):\n",
    "    \n",
    "    #defaults\n",
    "    default_config = { 'guidance_scale': 3, 'max_new_tokens': 256, 'do_sample': True }\n",
    "    default_texts = [\"Morning sunshine, beats, ukelele, happy swings\"]\n",
    "    \n",
    "    # obtain input data\n",
    "    if 'texts' in data.keys():\n",
    "        texts = data.pop('texts')\n",
    "    else:\n",
    "        texts = default_texts\n",
    "    \n",
    "    if 'config' in data.keys():\n",
    "        config = data.pop('config')\n",
    "    else:\n",
    "        config = default_config\n",
    "    \n",
    "    processor = AutoProcessor.from_pretrained(\"facebook/musicgen-large\")\n",
    "    inputs = processor(\n",
    "        text = texts, #[\"80s pop track with bassy drums and synth\", \"90s rock song with loud guitars and heavy drums\"],\n",
    "        padding=True,\n",
    "        return_tensors=\"pt\",\n",
    "    )\n",
    "    \n",
    "    assert type(config) == dict\n",
    "    if 'guidance_scale' in config.keys():\n",
    "        guidance_scale = config.pop('guidance_scale')\n",
    "    else:\n",
    "        guidance_scale = default_config.pop('guidance_scale')\n",
    "    \n",
    "    if 'max_new_tokens' in config.keys():\n",
    "        max_new_tokens = config.pop('max_new_tokens')\n",
    "    else:\n",
    "        max_new_tokens =  default_config.pop('max_new_tokens')\n",
    "\n",
    "    if 'do_sample' in config.keys():\n",
    "        do_sample = config.pop('do_sample')\n",
    "    else:\n",
    "        do_sample = default_config.pop('do_sample')\n",
    "    \n",
    "    processed_config = {'guidance_scale': guidance_scale, 'do_sample': do_sample, 'max_new_tokens': max_new_tokens}\n",
    "    return inputs, processed_config\n",
    "\n",
    "\n",
    "def upload_to_s3(wav_on_disk, bucket_name):\n",
    "    s3 = boto3.resource('s3')\n",
    "    target_file = wav_on_disk.split('/')[-1]\n",
    "    s3.Bucket(bucket_name).upload_file(wav_on_disk, f'musicgen_large/output/{target_file}')\n",
    "    return f\"s3://{bucket_name}/musicgen_large/output/{target_file}\"\n",
    "\n",
    "\n",
    "def delete_file_on_disk(filename):\n",
    "    if os.path.isfile(filename):\n",
    "        os.remove(filename)\n",
    "        \n",
    "\n",
    "def write_to_s3(sampling_rate, audio_values, bucket_name):\n",
    "    r = len(audio_values)\n",
    "    s3_wav_keys = []\n",
    "    s3_prefix = 'musicgen_large/output'\n",
    "    for i in range(r):\n",
    "        \n",
    "        # Write wav to Disk\n",
    "        prefix = str(uuid.uuid1())\n",
    "        wav_file = f\"{prefix}_{i}_musicgen_large_out.wav\"\n",
    "        wav_on_disk = f'/tmp/{wav_file}'\n",
    "        try:\n",
    "            #scipy.io.wavfile.write(wav_on_disk, rate=sampling_rate, data=audio_values[i, 0].numpy())\n",
    "            scipy.io.wavfile.write(wav_on_disk, rate=sampling_rate, data=audio_values[i, 0].cpu().numpy())\n",
    "        except:\n",
    "            wav_on_disk = f'/opt/ml/output/data/{wav_file}'\n",
    "            #scipy.io.wavfile.write(wav_on_disk, rate=sampling_rate, data=audio_values[0, 0].numpy())\n",
    "            scipy.io.wavfile.write(wav_on_disk, rate=sampling_rate, data=audio_values[i, 0].cpu().numpy())\n",
    "\n",
    "        # Upload to S3\n",
    "        upload_to_s3(wav_on_disk, bucket_name)\n",
    "        \n",
    "        # Clean up disk\n",
    "        delete_file_on_disk(wav_on_disk)\n",
    "        \n",
    "    return s3_wav_keys\n",
    "\n",
    "\n",
    "def predict_fn(data, model):\n",
    "    \n",
    "    # https://sagemaker.readthedocs.io/en/stable/api/inference/predictors.html#sagemaker.predictor.Predictor.predict\n",
    "    \n",
    "    bucket_name = data.pop('bucket_name', None)\n",
    "    \n",
    "    if not bucket_name:\n",
    "        raise ValueError(\"bucket_name is required ex: sagemaker_default_bucket_007\")\n",
    "        \n",
    "    inputs, processed_config = process_input(data)\n",
    "    \n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    audio_values = model.generate(**inputs.to(device), \n",
    "                                  max_new_tokens=processed_config.pop('max_new_tokens'), \n",
    "                                  guidance_scale = processed_config.pop('guidance_scale'),\n",
    "                                  do_sample = processed_config.pop('do_sample'))\n",
    "\n",
    "    sampling_rate = model.config.audio_encoder.sampling_rate\n",
    "    s3_wav_keys = write_to_s3(sampling_rate, audio_values, bucket_name)\n",
    "    return {\n",
    "        \"generated_outputs_s3\": s3_wav_keys,\n",
    "        \"audio_values\": audio_values\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5d35645-e796-40f3-bfe5-8dc8378da653",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%cd model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbe3098e-1194-4805-8cfd-f33880dd7211",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!rm model.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8be2a9d-63a6-4938-bbfb-7ab687ad69ca",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!rm -rf code/.ipynb_checkpoints*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20a8ea5b-753f-4ae8-aeff-226fad09eabd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!tar zcvf model.tar.gz *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de657b6f-7c22-4496-8c74-05d1661527c8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "import boto3\n",
    "\n",
    "sess = sagemaker.Session()\n",
    "\n",
    "sagemaker_session_bucket = None\n",
    "if sagemaker_session_bucket is None and sess is not None:\n",
    "    sagemaker_session_bucket = sess.default_bucket()\n",
    "\n",
    "try:\n",
    "    role = sagemaker.get_execution_role()\n",
    "except ValueError:\n",
    "    iam = boto3.client(\"iam\")\n",
    "    role = iam.get_role(RoleName=\"sagemaker_execution_role\")[\"Role\"][\"Arn\"]\n",
    "\n",
    "sess = sagemaker.Session(default_bucket=sagemaker_session_bucket)\n",
    "\n",
    "print(f\"sagemaker role arn: {role}\")\n",
    "print(f\"sagemaker bucket: {sess.default_bucket()}\")\n",
    "print(f\"sagemaker session region: {sess.boto_region_name}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89056fe5-98e8-44a6-b484-f01d83872293",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "musicgen_prefix = 'musicgen_large'\n",
    "s3_model_key = f'{musicgen_prefix}/model/model.tar.gz'\n",
    "s3_model_location = f\"s3://{sagemaker_session_bucket}/{s3_model_key}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c407864-cf11-4c09-9d59-645bfe187bf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "s3 = boto3.resource(\"s3\")\n",
    "s3.Bucket(sagemaker_session_bucket).upload_file(\"model.tar.gz\", s3_model_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "968baaea-6613-4f5e-9469-ccc55ea35ef7",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Async Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb012660-5957-4ced-b2f3-e1527d99839a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.huggingface.model import HuggingFaceModel\n",
    "from sagemaker.async_inference.async_inference_config import AsyncInferenceConfig\n",
    "from sagemaker.s3 import s3_path_join\n",
    "from sagemaker.utils import name_from_base\n",
    "\n",
    "async_endpoint_name = name_from_base(\"musicgen-large-v1-asyc\")\n",
    "\n",
    "# create Hugging Face Model Class\n",
    "huggingface_model = HuggingFaceModel(\n",
    "    name=async_endpoint_name,\n",
    "    model_data=s3_model_location,  # path to your model and script\n",
    "    role=role,  # iam role with permissions to create an Endpoint\n",
    "    transformers_version=\"4.28\",  # transformers version used\n",
    "    pytorch_version=\"2.0\",  # pytorch version used\n",
    "    py_version=\"py310\",  # python version used\n",
    ")\n",
    "\n",
    "# create async endpoint configuration\n",
    "async_config = AsyncInferenceConfig(\n",
    "    output_path=s3_path_join(\n",
    "        \"s3://\", sagemaker_session_bucket, \"musicgen_large/async_inference/music_output\"\n",
    "    ),  # Where our results will be stored\n",
    "    # Add nofitication SNS if needed\n",
    "    notification_config={\n",
    "        # \"SuccessTopic\": \"PUT YOUR SUCCESS SNS TOPIC ARN\",\n",
    "        # \"ErrorTopic\": \"PUT YOUR ERROR SNS TOPIC ARN\",\n",
    "    },  #  Notification configuration\n",
    ")\n",
    "\n",
    "# deploy the endpoint endpoint\n",
    "async_predictor = huggingface_model.deploy(\n",
    "    initial_instance_count=1,\n",
    "    instance_type=\"ml.g5.2xlarge\",\n",
    "    async_inference_config=async_config,\n",
    "    endpoint_name=async_endpoint_name,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ea3be25-db70-4e9c-9054-e3978ecd62b5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "endpoint_name=async_predictor.endpoint_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "626079df-5dec-4c67-be91-52698f52e567",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%store \\\n",
    "endpoint_name \\\n",
    "sagemaker_session_bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "214b74dd-b98d-4eda-80b5-1161eae18844",
   "metadata": {},
   "outputs": [],
   "source": [
    "endpoint_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c1a8edd-1e90-4de2-af2b-00eff26e33cb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   },
   {
    "_defaultOrder": 55,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 56,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4de.24xlarge",
    "vcpuNum": 96
   }
  ],
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Data Science 3.0)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-west-2:236514542706:image/sagemaker-data-science-310-v1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
